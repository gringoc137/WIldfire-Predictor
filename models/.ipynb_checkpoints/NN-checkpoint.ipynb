{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn.metrics as metrics\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>mask</th>\n",
       "      <th>lst</th>\n",
       "      <th>lstn</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>vcr</th>\n",
       "      <th>prec</th>\n",
       "      <th>ma_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.26000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>323.92000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>309.33877</td>\n",
       "      <td>297.900000</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.36000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>321.90000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        lat         lon  mask        lst        lstn    ndvi  \\\n",
       "0  2019-06-02  39.737500 -122.295833   9.0  310.26000  290.921693  0.3108   \n",
       "1  2019-06-10  39.737500 -122.295833   5.0  323.92000  290.921693  0.2526   \n",
       "2  2019-06-18  39.737500 -122.295833   5.0  309.33877  297.900000  0.2526   \n",
       "3  2019-06-02  39.729167 -122.295833   9.0  310.36000  290.921693  0.3198   \n",
       "4  2019-06-10  39.729167 -122.295833   5.0  321.90000  290.921693  0.2670   \n",
       "\n",
       "    vcr      prec  ma_cat  \n",
       "0  0.59  0.718065       1  \n",
       "1  0.59  0.000000       0  \n",
       "2  0.59  0.000000       0  \n",
       "3  0.57  0.718065       1  \n",
       "4  0.57  0.000000       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Mahe\\Desktop\\Wildfire-Predictor\\final.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['vcr', 'lst','ndvi','lstn','prec']] .values\n",
    "x=df[['vcr', 'lst','ndvi','lstn','prec']]\n",
    "y = df['ma_cat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63030991e-01,  1.63890259e-01, -7.74358640e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-3.63030991e-01,  2.59405503e+00, -1.12630579e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01],\n",
       "       [-3.63030991e-01, -3.03379665e-14, -1.12630579e+00,\n",
       "         2.02688551e+00, -5.90206435e-01],\n",
       "       [-4.71069833e-01,  1.81680631e-01, -7.19933824e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-4.71069833e-01,  2.23468952e+00, -1.03922608e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Before SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "1333/1333 [==============================] - 1s 590us/step - loss: 0.5131 - accuracy: 0.8927\n",
      "Epoch 2/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2780 - accuracy: 0.9415\n",
      "Epoch 3/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2301 - accuracy: 0.9415\n",
      "Epoch 4/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.2225 - accuracy: 0.9415\n",
      "Epoch 5/100\n",
      "1333/1333 [==============================] - 0s 168us/step - loss: 0.2199 - accuracy: 0.9415\n",
      "Epoch 6/100\n",
      "1333/1333 [==============================] - 0s 159us/step - loss: 0.2177 - accuracy: 0.9415\n",
      "Epoch 7/100\n",
      "1333/1333 [==============================] - 0s 217us/step - loss: 0.2164 - accuracy: 0.9415\n",
      "Epoch 8/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2146 - accuracy: 0.9415\n",
      "Epoch 9/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2139 - accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.2126 - accuracy: 0.9415\n",
      "Epoch 11/100\n",
      "1333/1333 [==============================] - 0s 163us/step - loss: 0.2116 - accuracy: 0.9415\n",
      "Epoch 12/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2107 - accuracy: 0.9415\n",
      "Epoch 13/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2102 - accuracy: 0.9415\n",
      "Epoch 14/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2093 - accuracy: 0.9415\n",
      "Epoch 15/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2085 - accuracy: 0.9415\n",
      "Epoch 16/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2069 - accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "1333/1333 [==============================] - 0s 148us/step - loss: 0.2065 - accuracy: 0.9415\n",
      "Epoch 19/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2058 - accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2051 - accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.2048 - accuracy: 0.9415\n",
      "Epoch 22/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2044 - accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2042 - accuracy: 0.9415\n",
      "Epoch 24/100\n",
      "1333/1333 [==============================] - 0s 145us/step - loss: 0.2034 - accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "1333/1333 [==============================] - 0s 151us/step - loss: 0.2030 - accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2026 - accuracy: 0.9415\n",
      "Epoch 27/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2019 - accuracy: 0.9415\n",
      "Epoch 28/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2017 - accuracy: 0.9415\n",
      "Epoch 29/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2013 - accuracy: 0.9415\n",
      "Epoch 30/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.2009 - accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2004 - accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2000 - accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1992 - accuracy: 0.9415\n",
      "Epoch 34/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1988 - accuracy: 0.9415\n",
      "Epoch 35/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1983 - accuracy: 0.9415\n",
      "Epoch 36/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1979 - accuracy: 0.9415\n",
      "Epoch 37/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1976 - accuracy: 0.9415\n",
      "Epoch 38/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1973 - accuracy: 0.9415\n",
      "Epoch 39/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1965 - accuracy: 0.9415\n",
      "Epoch 40/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1964 - accuracy: 0.9415\n",
      "Epoch 41/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1959 - accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 43/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1950 - accuracy: 0.9415\n",
      "Epoch 44/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 45/100\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.94 - 0s 127us/step - loss: 0.1943 - accuracy: 0.9415\n",
      "Epoch 46/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1936 - accuracy: 0.9415\n",
      "Epoch 47/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1933 - accuracy: 0.9415\n",
      "Epoch 48/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1924 - accuracy: 0.9415\n",
      "Epoch 49/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1925 - accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1922 - accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1915 - accuracy: 0.9415\n",
      "Epoch 52/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1909 - accuracy: 0.9415\n",
      "Epoch 53/100\n",
      "1333/1333 [==============================] - 0s 166us/step - loss: 0.1899 - accuracy: 0.9415\n",
      "Epoch 54/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1896 - accuracy: 0.9415\n",
      "Epoch 55/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1895 - accuracy: 0.9415\n",
      "Epoch 56/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1886 - accuracy: 0.9415\n",
      "Epoch 57/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1884 - accuracy: 0.9415\n",
      "Epoch 58/100\n",
      "1333/1333 [==============================] - 0s 143us/step - loss: 0.1879 - accuracy: 0.9415\n",
      "Epoch 59/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1877 - accuracy: 0.9415\n",
      "Epoch 60/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.1870 - accuracy: 0.9415\n",
      "Epoch 61/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1859 - accuracy: 0.9415\n",
      "Epoch 62/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1851 - accuracy: 0.9415\n",
      "Epoch 63/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1850 - accuracy: 0.9415\n",
      "Epoch 64/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.1849 - accuracy: 0.9415\n",
      "Epoch 65/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1836 - accuracy: 0.9422\n",
      "Epoch 66/100\n",
      "1333/1333 [==============================] - 0s 140us/step - loss: 0.1835 - accuracy: 0.9415\n",
      "Epoch 67/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1834 - accuracy: 0.9422\n",
      "Epoch 68/100\n",
      "1333/1333 [==============================] - 0s 142us/step - loss: 0.1828 - accuracy: 0.9422\n",
      "Epoch 69/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1814 - accuracy: 0.9422\n",
      "Epoch 70/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1818 - accuracy: 0.9430\n",
      "Epoch 71/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1815 - accuracy: 0.9415\n",
      "Epoch 72/100\n",
      "1333/1333 [==============================] - 0s 181us/step - loss: 0.1802 - accuracy: 0.9430\n",
      "Epoch 73/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1800 - accuracy: 0.9415\n",
      "Epoch 74/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1793 - accuracy: 0.9430\n",
      "Epoch 75/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1798 - accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1790 - accuracy: 0.9430\n",
      "Epoch 77/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1786 - accuracy: 0.9422\n",
      "Epoch 78/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1774 - accuracy: 0.9430\n",
      "Epoch 79/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1772 - accuracy: 0.94300s - loss: 0.1697 - accuracy: 0.\n",
      "Epoch 80/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1772 - accuracy: 0.9422\n",
      "Epoch 81/100\n",
      "1333/1333 [==============================] - 0s 123us/step - loss: 0.1760 - accuracy: 0.9452\n",
      "Epoch 82/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1756 - accuracy: 0.9460\n",
      "Epoch 83/100\n",
      "1333/1333 [==============================] - 0s 173us/step - loss: 0.1769 - accuracy: 0.9430\n",
      "Epoch 84/100\n",
      "1333/1333 [==============================] - 0s 169us/step - loss: 0.1752 - accuracy: 0.9445\n",
      "Epoch 85/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1752 - accuracy: 0.9452\n",
      "Epoch 86/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1754 - accuracy: 0.9445\n",
      "Epoch 87/100\n",
      "1333/1333 [==============================] - 0s 172us/step - loss: 0.1740 - accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "1333/1333 [==============================] - 0s 194us/step - loss: 0.1737 - accuracy: 0.9445\n",
      "Epoch 89/100\n",
      "1333/1333 [==============================] - 0s 175us/step - loss: 0.1731 - accuracy: 0.9437\n",
      "Epoch 90/100\n",
      "1333/1333 [==============================] - 0s 178us/step - loss: 0.1736 - accuracy: 0.9437\n",
      "Epoch 91/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.1726 - accuracy: 0.9460\n",
      "Epoch 92/100\n",
      "1333/1333 [==============================] - 0s 186us/step - loss: 0.1724 - accuracy: 0.9445\n",
      "Epoch 93/100\n",
      "1333/1333 [==============================] - 0s 190us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 94/100\n",
      "1333/1333 [==============================] - 0s 184us/step - loss: 0.1720 - accuracy: 0.9452\n",
      "Epoch 95/100\n",
      "1333/1333 [==============================] - 0s 182us/step - loss: 0.1718 - accuracy: 0.9452\n",
      "Epoch 96/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "1333/1333 [==============================] - 0s 161us/step - loss: 0.1708 - accuracy: 0.9452\n",
      "Epoch 98/100\n",
      "1333/1333 [==============================] - 0s 162us/step - loss: 0.1713 - accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "1333/1333 [==============================] - 0s 124us/step - loss: 0.1711 - accuracy: 0.9452\n",
      "Epoch 100/100\n",
      "1333/1333 [==============================] - 0s 147us/step - loss: 0.1703 - accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x190f857b6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9458041958041958\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       541\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.95       572\n",
      "   macro avg       0.47      0.50      0.49       572\n",
      "weighted avg       0.89      0.95      0.92       572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Sequential()\n",
    "models.add(Dense(12, input_dim=5, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "models.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2510/2510 [==============================] - 1s 223us/step - loss: 0.6856 - accuracy: 0.5904\n",
      "Epoch 2/100\n",
      "2510/2510 [==============================] - 0s 140us/step - loss: 0.6456 - accuracy: 0.6550\n",
      "Epoch 3/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.6121 - accuracy: 0.7016\n",
      "Epoch 4/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.5788 - accuracy: 0.7243\n",
      "Epoch 5/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.5376 - accuracy: 0.7406\n",
      "Epoch 6/100\n",
      "2510/2510 [==============================] - 0s 144us/step - loss: 0.4980 - accuracy: 0.7526\n",
      "Epoch 7/100\n",
      "2510/2510 [==============================] - 0s 151us/step - loss: 0.4675 - accuracy: 0.7741\n",
      "Epoch 8/100\n",
      "2510/2510 [==============================] - 0s 136us/step - loss: 0.4481 - accuracy: 0.7781\n",
      "Epoch 9/100\n",
      "2510/2510 [==============================] - 0s 136us/step - loss: 0.4351 - accuracy: 0.7861\n",
      "Epoch 10/100\n",
      "2510/2510 [==============================] - 0s 131us/step - loss: 0.4234 - accuracy: 0.7900\n",
      "Epoch 11/100\n",
      "2510/2510 [==============================] - 0s 177us/step - loss: 0.4126 - accuracy: 0.7908\n",
      "Epoch 12/100\n",
      "2510/2510 [==============================] - 0s 163us/step - loss: 0.4082 - accuracy: 0.7944\n",
      "Epoch 13/100\n",
      "2510/2510 [==============================] - 1s 219us/step - loss: 0.4009 - accuracy: 0.7972\n",
      "Epoch 14/100\n",
      "2510/2510 [==============================] - 1s 206us/step - loss: 0.3952 - accuracy: 0.8020\n",
      "Epoch 15/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.3924 - accuracy: 0.8028\n",
      "Epoch 16/100\n",
      "2510/2510 [==============================] - 0s 148us/step - loss: 0.3886 - accuracy: 0.8100\n",
      "Epoch 17/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3844 - accuracy: 0.8080\n",
      "Epoch 18/100\n",
      "2510/2510 [==============================] - 0s 139us/step - loss: 0.3808 - accuracy: 0.8072\n",
      "Epoch 19/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.3761 - accuracy: 0.8076\n",
      "Epoch 20/100\n",
      "2510/2510 [==============================] - 0s 164us/step - loss: 0.3726 - accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.3684 - accuracy: 0.8131\n",
      "Epoch 22/100\n",
      "2510/2510 [==============================] - 0s 129us/step - loss: 0.3656 - accuracy: 0.8151\n",
      "Epoch 23/100\n",
      "2510/2510 [==============================] - 0s 131us/step - loss: 0.3611 - accuracy: 0.8199\n",
      "Epoch 24/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3602 - accuracy: 0.8231\n",
      "Epoch 25/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3576 - accuracy: 0.8207\n",
      "Epoch 26/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3525 - accuracy: 0.8219\n",
      "Epoch 27/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3504 - accuracy: 0.8307\n",
      "Epoch 28/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3484 - accuracy: 0.8335\n",
      "Epoch 29/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3476 - accuracy: 0.8343\n",
      "Epoch 30/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3420 - accuracy: 0.8319\n",
      "Epoch 31/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3418 - accuracy: 0.8323\n",
      "Epoch 32/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3412 - accuracy: 0.8375\n",
      "Epoch 33/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3387 - accuracy: 0.8378\n",
      "Epoch 34/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3342 - accuracy: 0.8390\n",
      "Epoch 35/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3322 - accuracy: 0.8446\n",
      "Epoch 36/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3306 - accuracy: 0.8434\n",
      "Epoch 37/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3289 - accuracy: 0.8494\n",
      "Epoch 38/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3257 - accuracy: 0.8474\n",
      "Epoch 39/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3211 - accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3204 - accuracy: 0.8574\n",
      "Epoch 41/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3176 - accuracy: 0.8534\n",
      "Epoch 42/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3152 - accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.3125 - accuracy: 0.8538\n",
      "Epoch 44/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3091 - accuracy: 0.8602\n",
      "Epoch 45/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3109 - accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "2510/2510 [==============================] - 0s 141us/step - loss: 0.3070 - accuracy: 0.8590\n",
      "Epoch 47/100\n",
      "2510/2510 [==============================] - 0s 157us/step - loss: 0.3035 - accuracy: 0.8669\n",
      "Epoch 48/100\n",
      "2510/2510 [==============================] - 0s 145us/step - loss: 0.3021 - accuracy: 0.8689\n",
      "Epoch 49/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3020 - accuracy: 0.8645\n",
      "Epoch 50/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3007 - accuracy: 0.8673\n",
      "Epoch 51/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2982 - accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2960 - accuracy: 0.8689\n",
      "Epoch 53/100\n",
      "2510/2510 [==============================] - 0s 129us/step - loss: 0.2965 - accuracy: 0.8606\n",
      "Epoch 54/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2929 - accuracy: 0.8685\n",
      "Epoch 55/100\n",
      "2510/2510 [==============================] - 0s 129us/step - loss: 0.2912 - accuracy: 0.8705\n",
      "Epoch 56/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2889 - accuracy: 0.8685\n",
      "Epoch 57/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2895 - accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.2863 - accuracy: 0.8697\n",
      "Epoch 59/100\n",
      "2510/2510 [==============================] - 0s 152us/step - loss: 0.2847 - accuracy: 0.8713\n",
      "Epoch 60/100\n",
      "2510/2510 [==============================] - 0s 169us/step - loss: 0.2822 - accuracy: 0.8785\n",
      "Epoch 61/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.2829 - accuracy: 0.8793\n",
      "Epoch 62/100\n",
      "2510/2510 [==============================] - 0s 155us/step - loss: 0.2797 - accuracy: 0.8781\n",
      "Epoch 63/100\n",
      "2510/2510 [==============================] - 0s 131us/step - loss: 0.2809 - accuracy: 0.8733\n",
      "Epoch 64/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2803 - accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2767 - accuracy: 0.8825\n",
      "Epoch 66/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2750 - accuracy: 0.8821\n",
      "Epoch 67/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2722 - accuracy: 0.8809\n",
      "Epoch 68/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2737 - accuracy: 0.8789\n",
      "Epoch 69/100\n",
      "2510/2510 [==============================] - 0s 133us/step - loss: 0.2705 - accuracy: 0.8793\n",
      "Epoch 70/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2693 - accuracy: 0.8781\n",
      "Epoch 71/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2686 - accuracy: 0.8873\n",
      "Epoch 72/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.2667 - accuracy: 0.8876\n",
      "Epoch 73/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2633 - accuracy: 0.8900\n",
      "Epoch 74/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2645 - accuracy: 0.8841\n",
      "Epoch 75/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2614 - accuracy: 0.8924\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2602 - accuracy: 0.8896\n",
      "Epoch 77/100\n",
      "2510/2510 [==============================] - 0s 166us/step - loss: 0.2587 - accuracy: 0.89200s - loss: 0.2556 - accu\n",
      "Epoch 78/100\n",
      "2510/2510 [==============================] - 0s 134us/step - loss: 0.2588 - accuracy: 0.8888\n",
      "Epoch 79/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2553 - accuracy: 0.8932\n",
      "Epoch 80/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2575 - accuracy: 0.8920\n",
      "Epoch 81/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2536 - accuracy: 0.8916\n",
      "Epoch 82/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2523 - accuracy: 0.8932\n",
      "Epoch 83/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2470 - accuracy: 0.8984\n",
      "Epoch 84/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2492 - accuracy: 0.8960\n",
      "Epoch 85/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2469 - accuracy: 0.8996\n",
      "Epoch 86/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2460 - accuracy: 0.8988\n",
      "Epoch 87/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2473 - accuracy: 0.8968\n",
      "Epoch 88/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2437 - accuracy: 0.9004\n",
      "Epoch 89/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2418 - accuracy: 0.8956\n",
      "Epoch 90/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2422 - accuracy: 0.8972\n",
      "Epoch 91/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2435 - accuracy: 0.8936\n",
      "Epoch 92/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.2391 - accuracy: 0.8984\n",
      "Epoch 93/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.2396 - accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.2388 - accuracy: 0.9020\n",
      "Epoch 95/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2356 - accuracy: 0.9024\n",
      "Epoch 96/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2360 - accuracy: 0.9044\n",
      "Epoch 97/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2342 - accuracy: 0.9012\n",
      "Epoch 98/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2325 - accuracy: 0.9036\n",
      "Epoch 99/100\n",
      "2510/2510 [==============================] - 0s 141us/step - loss: 0.2298 - accuracy: 0.9052\n",
      "Epoch 100/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2340 - accuracy: 0.9008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20f1b143e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = models.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8286713286713286\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       541\n",
      "           1       0.16      0.52      0.25        31\n",
      "\n",
      "    accuracy                           0.83       572\n",
      "   macro avg       0.56      0.68      0.57       572\n",
      "weighted avg       0.92      0.83      0.87       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 16  15]\n",
      " [ 83 458]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
