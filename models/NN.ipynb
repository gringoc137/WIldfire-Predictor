{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn.metrics as metrics\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>mask</th>\n",
       "      <th>lst</th>\n",
       "      <th>lstn</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>vcr</th>\n",
       "      <th>prec</th>\n",
       "      <th>ma_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.26000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>323.92000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>309.33877</td>\n",
       "      <td>297.900000</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.36000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>321.90000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        lat         lon  mask        lst        lstn    ndvi  \\\n",
       "0  2019-06-02  39.737500 -122.295833   9.0  310.26000  290.921693  0.3108   \n",
       "1  2019-06-10  39.737500 -122.295833   5.0  323.92000  290.921693  0.2526   \n",
       "2  2019-06-18  39.737500 -122.295833   5.0  309.33877  297.900000  0.2526   \n",
       "3  2019-06-02  39.729167 -122.295833   9.0  310.36000  290.921693  0.3198   \n",
       "4  2019-06-10  39.729167 -122.295833   5.0  321.90000  290.921693  0.2670   \n",
       "\n",
       "    vcr      prec  ma_cat  \n",
       "0  0.59  0.718065       1  \n",
       "1  0.59  0.000000       0  \n",
       "2  0.59  0.000000       0  \n",
       "3  0.57  0.718065       1  \n",
       "4  0.57  0.000000       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['vcr', 'lst','ndvi','lstn','prec']] .values\n",
    "x=df[['vcr', 'lst','ndvi','lstn','prec']]\n",
    "y = df['ma_cat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63030991e-01,  1.63890259e-01, -7.74358640e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-3.63030991e-01,  2.59405503e+00, -1.12630579e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01],\n",
       "       [-3.63030991e-01, -3.03379665e-14, -1.12630579e+00,\n",
       "         2.02688551e+00, -5.90206435e-01],\n",
       "       [-4.71069833e-01,  1.81680631e-01, -7.19933824e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-4.71069833e-01,  2.23468952e+00, -1.03922608e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "1333/1333 [==============================] - 1s 590us/step - loss: 0.5131 - accuracy: 0.8927\n",
      "Epoch 2/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2780 - accuracy: 0.9415\n",
      "Epoch 3/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2301 - accuracy: 0.9415\n",
      "Epoch 4/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.2225 - accuracy: 0.9415\n",
      "Epoch 5/100\n",
      "1333/1333 [==============================] - 0s 168us/step - loss: 0.2199 - accuracy: 0.9415\n",
      "Epoch 6/100\n",
      "1333/1333 [==============================] - 0s 159us/step - loss: 0.2177 - accuracy: 0.9415\n",
      "Epoch 7/100\n",
      "1333/1333 [==============================] - 0s 217us/step - loss: 0.2164 - accuracy: 0.9415\n",
      "Epoch 8/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2146 - accuracy: 0.9415\n",
      "Epoch 9/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2139 - accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.2126 - accuracy: 0.9415\n",
      "Epoch 11/100\n",
      "1333/1333 [==============================] - 0s 163us/step - loss: 0.2116 - accuracy: 0.9415\n",
      "Epoch 12/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2107 - accuracy: 0.9415\n",
      "Epoch 13/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2102 - accuracy: 0.9415\n",
      "Epoch 14/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2093 - accuracy: 0.9415\n",
      "Epoch 15/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2085 - accuracy: 0.9415\n",
      "Epoch 16/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2069 - accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "1333/1333 [==============================] - 0s 148us/step - loss: 0.2065 - accuracy: 0.9415\n",
      "Epoch 19/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2058 - accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2051 - accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.2048 - accuracy: 0.9415\n",
      "Epoch 22/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2044 - accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2042 - accuracy: 0.9415\n",
      "Epoch 24/100\n",
      "1333/1333 [==============================] - 0s 145us/step - loss: 0.2034 - accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "1333/1333 [==============================] - 0s 151us/step - loss: 0.2030 - accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2026 - accuracy: 0.9415\n",
      "Epoch 27/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2019 - accuracy: 0.9415\n",
      "Epoch 28/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2017 - accuracy: 0.9415\n",
      "Epoch 29/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2013 - accuracy: 0.9415\n",
      "Epoch 30/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.2009 - accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2004 - accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2000 - accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1992 - accuracy: 0.9415\n",
      "Epoch 34/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1988 - accuracy: 0.9415\n",
      "Epoch 35/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1983 - accuracy: 0.9415\n",
      "Epoch 36/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1979 - accuracy: 0.9415\n",
      "Epoch 37/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1976 - accuracy: 0.9415\n",
      "Epoch 38/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1973 - accuracy: 0.9415\n",
      "Epoch 39/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1965 - accuracy: 0.9415\n",
      "Epoch 40/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1964 - accuracy: 0.9415\n",
      "Epoch 41/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1959 - accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 43/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1950 - accuracy: 0.9415\n",
      "Epoch 44/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 45/100\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.94 - 0s 127us/step - loss: 0.1943 - accuracy: 0.9415\n",
      "Epoch 46/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1936 - accuracy: 0.9415\n",
      "Epoch 47/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1933 - accuracy: 0.9415\n",
      "Epoch 48/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1924 - accuracy: 0.9415\n",
      "Epoch 49/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1925 - accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1922 - accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1915 - accuracy: 0.9415\n",
      "Epoch 52/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1909 - accuracy: 0.9415\n",
      "Epoch 53/100\n",
      "1333/1333 [==============================] - 0s 166us/step - loss: 0.1899 - accuracy: 0.9415\n",
      "Epoch 54/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1896 - accuracy: 0.9415\n",
      "Epoch 55/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1895 - accuracy: 0.9415\n",
      "Epoch 56/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1886 - accuracy: 0.9415\n",
      "Epoch 57/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1884 - accuracy: 0.9415\n",
      "Epoch 58/100\n",
      "1333/1333 [==============================] - 0s 143us/step - loss: 0.1879 - accuracy: 0.9415\n",
      "Epoch 59/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1877 - accuracy: 0.9415\n",
      "Epoch 60/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.1870 - accuracy: 0.9415\n",
      "Epoch 61/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1859 - accuracy: 0.9415\n",
      "Epoch 62/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1851 - accuracy: 0.9415\n",
      "Epoch 63/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1850 - accuracy: 0.9415\n",
      "Epoch 64/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.1849 - accuracy: 0.9415\n",
      "Epoch 65/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1836 - accuracy: 0.9422\n",
      "Epoch 66/100\n",
      "1333/1333 [==============================] - 0s 140us/step - loss: 0.1835 - accuracy: 0.9415\n",
      "Epoch 67/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1834 - accuracy: 0.9422\n",
      "Epoch 68/100\n",
      "1333/1333 [==============================] - 0s 142us/step - loss: 0.1828 - accuracy: 0.9422\n",
      "Epoch 69/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1814 - accuracy: 0.9422\n",
      "Epoch 70/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1818 - accuracy: 0.9430\n",
      "Epoch 71/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1815 - accuracy: 0.9415\n",
      "Epoch 72/100\n",
      "1333/1333 [==============================] - 0s 181us/step - loss: 0.1802 - accuracy: 0.9430\n",
      "Epoch 73/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1800 - accuracy: 0.9415\n",
      "Epoch 74/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1793 - accuracy: 0.9430\n",
      "Epoch 75/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1798 - accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1790 - accuracy: 0.9430\n",
      "Epoch 77/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1786 - accuracy: 0.9422\n",
      "Epoch 78/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1774 - accuracy: 0.9430\n",
      "Epoch 79/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1772 - accuracy: 0.94300s - loss: 0.1697 - accuracy: 0.\n",
      "Epoch 80/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1772 - accuracy: 0.9422\n",
      "Epoch 81/100\n",
      "1333/1333 [==============================] - 0s 123us/step - loss: 0.1760 - accuracy: 0.9452\n",
      "Epoch 82/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1756 - accuracy: 0.9460\n",
      "Epoch 83/100\n",
      "1333/1333 [==============================] - 0s 173us/step - loss: 0.1769 - accuracy: 0.9430\n",
      "Epoch 84/100\n",
      "1333/1333 [==============================] - 0s 169us/step - loss: 0.1752 - accuracy: 0.9445\n",
      "Epoch 85/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1752 - accuracy: 0.9452\n",
      "Epoch 86/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1754 - accuracy: 0.9445\n",
      "Epoch 87/100\n",
      "1333/1333 [==============================] - 0s 172us/step - loss: 0.1740 - accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "1333/1333 [==============================] - 0s 194us/step - loss: 0.1737 - accuracy: 0.9445\n",
      "Epoch 89/100\n",
      "1333/1333 [==============================] - 0s 175us/step - loss: 0.1731 - accuracy: 0.9437\n",
      "Epoch 90/100\n",
      "1333/1333 [==============================] - 0s 178us/step - loss: 0.1736 - accuracy: 0.9437\n",
      "Epoch 91/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.1726 - accuracy: 0.9460\n",
      "Epoch 92/100\n",
      "1333/1333 [==============================] - 0s 186us/step - loss: 0.1724 - accuracy: 0.9445\n",
      "Epoch 93/100\n",
      "1333/1333 [==============================] - 0s 190us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 94/100\n",
      "1333/1333 [==============================] - 0s 184us/step - loss: 0.1720 - accuracy: 0.9452\n",
      "Epoch 95/100\n",
      "1333/1333 [==============================] - 0s 182us/step - loss: 0.1718 - accuracy: 0.9452\n",
      "Epoch 96/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "1333/1333 [==============================] - 0s 161us/step - loss: 0.1708 - accuracy: 0.9452\n",
      "Epoch 98/100\n",
      "1333/1333 [==============================] - 0s 162us/step - loss: 0.1713 - accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "1333/1333 [==============================] - 0s 124us/step - loss: 0.1711 - accuracy: 0.9452\n",
      "Epoch 100/100\n",
      "1333/1333 [==============================] - 0s 147us/step - loss: 0.1703 - accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x190f857b6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9458041958041958\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       541\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.95       572\n",
      "   macro avg       0.47      0.50      0.49       572\n",
      "weighted avg       0.89      0.95      0.92       572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  17]\n",
      " [100 441]]\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Sequential()\n",
    "models.add(Dense(12, input_dim=5, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.5464 - accuracy: 0.7386\n",
      "Epoch 2/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.4839 - accuracy: 0.7629\n",
      "Epoch 3/100\n",
      "2510/2510 [==============================] - 0s 136us/step - loss: 0.4724 - accuracy: 0.7681\n",
      "Epoch 4/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.4629 - accuracy: 0.7725\n",
      "Epoch 5/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.4559 - accuracy: 0.7765\n",
      "Epoch 6/100\n",
      "2510/2510 [==============================] - 0s 139us/step - loss: 0.4501 - accuracy: 0.7793\n",
      "Epoch 7/100\n",
      "2510/2510 [==============================] - 0s 118us/step - loss: 0.4445 - accuracy: 0.7773\n",
      "Epoch 8/100\n",
      "2510/2510 [==============================] - 0s 118us/step - loss: 0.4419 - accuracy: 0.7837\n",
      "Epoch 9/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.4391 - accuracy: 0.7829\n",
      "Epoch 10/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.4329 - accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.4303 - accuracy: 0.7869\n",
      "Epoch 12/100\n",
      "2510/2510 [==============================] - 0s 160us/step - loss: 0.4261 - accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "2510/2510 [==============================] - 0s 147us/step - loss: 0.4216 - accuracy: 0.7900\n",
      "Epoch 14/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.4181 - accuracy: 0.7924\n",
      "Epoch 15/100\n",
      "2510/2510 [==============================] - 0s 194us/step - loss: 0.4151 - accuracy: 0.7948\n",
      "Epoch 16/100\n",
      "2510/2510 [==============================] - 0s 177us/step - loss: 0.4106 - accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "2510/2510 [==============================] - 0s 166us/step - loss: 0.4080 - accuracy: 0.8012\n",
      "Epoch 18/100\n",
      "2510/2510 [==============================] - 0s 150us/step - loss: 0.4022 - accuracy: 0.8008\n",
      "Epoch 19/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.3989 - accuracy: 0.8040\n",
      "Epoch 20/100\n",
      "2510/2510 [==============================] - 0s 138us/step - loss: 0.3948 - accuracy: 0.8092\n",
      "Epoch 21/100\n",
      "2510/2510 [==============================] - 0s 141us/step - loss: 0.3916 - accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "2510/2510 [==============================] - 0s 145us/step - loss: 0.3873 - accuracy: 0.8227\n",
      "Epoch 23/100\n",
      "2510/2510 [==============================] - 0s 152us/step - loss: 0.3842 - accuracy: 0.8215\n",
      "Epoch 24/100\n",
      "2510/2510 [==============================] - 0s 148us/step - loss: 0.3812 - accuracy: 0.8247\n",
      "Epoch 25/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.3779 - accuracy: 0.8283\n",
      "Epoch 26/100\n",
      "2510/2510 [==============================] - 0s 151us/step - loss: 0.3744 - accuracy: 0.8359\n",
      "Epoch 27/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3728 - accuracy: 0.8307\n",
      "Epoch 28/100\n",
      "2510/2510 [==============================] - 0s 134us/step - loss: 0.3699 - accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.3679 - accuracy: 0.8331\n",
      "Epoch 30/100\n",
      "2510/2510 [==============================] - 0s 117us/step - loss: 0.3662 - accuracy: 0.8382\n",
      "Epoch 31/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3646 - accuracy: 0.8371\n",
      "Epoch 32/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.3604 - accuracy: 0.8418\n",
      "Epoch 33/100\n",
      "2510/2510 [==============================] - 0s 117us/step - loss: 0.3592 - accuracy: 0.8398\n",
      "Epoch 34/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.3558 - accuracy: 0.8378\n",
      "Epoch 35/100\n",
      "2510/2510 [==============================] - 0s 118us/step - loss: 0.3543 - accuracy: 0.8406\n",
      "Epoch 36/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3535 - accuracy: 0.8430\n",
      "Epoch 37/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.3510 - accuracy: 0.8430\n",
      "Epoch 38/100\n",
      "2510/2510 [==============================] - 0s 134us/step - loss: 0.3485 - accuracy: 0.8450\n",
      "Epoch 39/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3465 - accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3448 - accuracy: 0.8470\n",
      "Epoch 41/100\n",
      "2510/2510 [==============================] - 0s 134us/step - loss: 0.3444 - accuracy: 0.8446\n",
      "Epoch 42/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3421 - accuracy: 0.8474\n",
      "Epoch 43/100\n",
      "2510/2510 [==============================] - 0s 147us/step - loss: 0.3400 - accuracy: 0.8494\n",
      "Epoch 44/100\n",
      "2510/2510 [==============================] - 0s 145us/step - loss: 0.3398 - accuracy: 0.8458\n",
      "Epoch 45/100\n",
      "2510/2510 [==============================] - 0s 134us/step - loss: 0.3376 - accuracy: 0.8474\n",
      "Epoch 46/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.3345 - accuracy: 0.8514\n",
      "Epoch 47/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.3335 - accuracy: 0.8498\n",
      "Epoch 48/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3313 - accuracy: 0.8466\n",
      "Epoch 49/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.3292 - accuracy: 0.8538\n",
      "Epoch 50/100\n",
      "2510/2510 [==============================] - 0s 131us/step - loss: 0.3288 - accuracy: 0.8558\n",
      "Epoch 51/100\n",
      "2510/2510 [==============================] - 0s 117us/step - loss: 0.3271 - accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3265 - accuracy: 0.8506\n",
      "Epoch 53/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.3247 - accuracy: 0.8586\n",
      "Epoch 54/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.3233 - accuracy: 0.8542\n",
      "Epoch 55/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3221 - accuracy: 0.8566\n",
      "Epoch 56/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.3209 - accuracy: 0.8514\n",
      "Epoch 57/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.3196 - accuracy: 0.8518\n",
      "Epoch 58/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3176 - accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3168 - accuracy: 0.8633\n",
      "Epoch 60/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.3146 - accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "2510/2510 [==============================] - 0s 144us/step - loss: 0.3135 - accuracy: 0.8578\n",
      "Epoch 62/100\n",
      "2510/2510 [==============================] - 0s 162us/step - loss: 0.3139 - accuracy: 0.8590\n",
      "Epoch 63/100\n",
      "2510/2510 [==============================] - 0s 173us/step - loss: 0.3111 - accuracy: 0.8602\n",
      "Epoch 64/100\n",
      "2510/2510 [==============================] - 0s 173us/step - loss: 0.3110 - accuracy: 0.86250s - loss: 0.2971 - accu\n",
      "Epoch 65/100\n",
      "2510/2510 [==============================] - 0s 149us/step - loss: 0.3098 - accuracy: 0.8637\n",
      "Epoch 66/100\n",
      "2510/2510 [==============================] - 0s 152us/step - loss: 0.3077 - accuracy: 0.8625\n",
      "Epoch 67/100\n",
      "2510/2510 [==============================] - 0s 184us/step - loss: 0.3082 - accuracy: 0.8641\n",
      "Epoch 68/100\n",
      "2510/2510 [==============================] - 0s 174us/step - loss: 0.3073 - accuracy: 0.8657\n",
      "Epoch 69/100\n",
      "2510/2510 [==============================] - 0s 141us/step - loss: 0.3053 - accuracy: 0.8645\n",
      "Epoch 70/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.3041 - accuracy: 0.8677\n",
      "Epoch 71/100\n",
      "2510/2510 [==============================] - 0s 133us/step - loss: 0.3029 - accuracy: 0.8653\n",
      "Epoch 72/100\n",
      "2510/2510 [==============================] - 0s 153us/step - loss: 0.3033 - accuracy: 0.8661\n",
      "Epoch 73/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.3032 - accuracy: 0.8657\n",
      "Epoch 74/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3013 - accuracy: 0.8697\n",
      "Epoch 75/100\n",
      "2510/2510 [==============================] - 0s 146us/step - loss: 0.3014 - accuracy: 0.8673\n",
      "Epoch 76/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2998 - accuracy: 0.8657\n",
      "Epoch 77/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2983 - accuracy: 0.8661\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510/2510 [==============================] - 0s 131us/step - loss: 0.2974 - accuracy: 0.8657\n",
      "Epoch 79/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.2965 - accuracy: 0.8689\n",
      "Epoch 80/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2964 - accuracy: 0.8657\n",
      "Epoch 81/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.2955 - accuracy: 0.8677\n",
      "Epoch 82/100\n",
      "2510/2510 [==============================] - 0s 118us/step - loss: 0.2945 - accuracy: 0.8689\n",
      "Epoch 83/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.2963 - accuracy: 0.8657\n",
      "Epoch 84/100\n",
      "2510/2510 [==============================] - 0s 140us/step - loss: 0.2953 - accuracy: 0.8693\n",
      "Epoch 85/100\n",
      "2510/2510 [==============================] - 0s 117us/step - loss: 0.2938 - accuracy: 0.8681\n",
      "Epoch 86/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2938 - accuracy: 0.8689\n",
      "Epoch 87/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2928 - accuracy: 0.8729\n",
      "Epoch 88/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2942 - accuracy: 0.8657\n",
      "Epoch 89/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.2930 - accuracy: 0.8713\n",
      "Epoch 90/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.2900 - accuracy: 0.8713\n",
      "Epoch 91/100\n",
      "2510/2510 [==============================] - 0s 118us/step - loss: 0.2899 - accuracy: 0.8729\n",
      "Epoch 92/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2890 - accuracy: 0.8729\n",
      "Epoch 93/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.2886 - accuracy: 0.8729\n",
      "Epoch 94/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2901 - accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.2891 - accuracy: 0.8729\n",
      "Epoch 96/100\n",
      "2510/2510 [==============================] - 0s 153us/step - loss: 0.2869 - accuracy: 0.8701\n",
      "Epoch 97/100\n",
      "2510/2510 [==============================] - 0s 149us/step - loss: 0.2878 - accuracy: 0.8753\n",
      "Epoch 98/100\n",
      "2510/2510 [==============================] - 0s 148us/step - loss: 0.2860 - accuracy: 0.8737\n",
      "Epoch 99/100\n",
      "2510/2510 [==============================] - 0s 164us/step - loss: 0.2891 - accuracy: 0.8713\n",
      "Epoch 100/100\n",
      "2510/2510 [==============================] - 0s 138us/step - loss: 0.2866 - accuracy: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x190f8a149e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7954545454545454\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88       541\n",
      "           1       0.12      0.45      0.19        31\n",
      "\n",
      "    accuracy                           0.80       572\n",
      "   macro avg       0.54      0.63      0.54       572\n",
      "weighted avg       0.92      0.80      0.85       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 14  17]\n",
      " [100 441]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
