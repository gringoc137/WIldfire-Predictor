{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn.metrics as metrics\n",
    "import itertools\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>mask</th>\n",
       "      <th>lst</th>\n",
       "      <th>lstn</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>vcr</th>\n",
       "      <th>prec</th>\n",
       "      <th>ma_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.26000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>323.92000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>39.737500</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>309.33877</td>\n",
       "      <td>297.900000</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>310.36000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.718065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>-122.295833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>321.90000</td>\n",
       "      <td>290.921693</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        lat         lon  mask        lst        lstn    ndvi  \\\n",
       "0  2019-06-02  39.737500 -122.295833   9.0  310.26000  290.921693  0.3108   \n",
       "1  2019-06-10  39.737500 -122.295833   5.0  323.92000  290.921693  0.2526   \n",
       "2  2019-06-18  39.737500 -122.295833   5.0  309.33877  297.900000  0.2526   \n",
       "3  2019-06-02  39.729167 -122.295833   9.0  310.36000  290.921693  0.3198   \n",
       "4  2019-06-10  39.729167 -122.295833   5.0  321.90000  290.921693  0.2670   \n",
       "\n",
       "    vcr      prec  ma_cat  \n",
       "0  0.59  0.718065       1  \n",
       "1  0.59  0.000000       0  \n",
       "2  0.59  0.000000       0  \n",
       "3  0.57  0.718065       1  \n",
       "4  0.57  0.000000       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Mahe\\Desktop\\Wildfire-Predictor\\final.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['vcr', 'lst','ndvi','lstn','prec']] .values\n",
    "x=df[['vcr', 'lst','ndvi','lstn','prec']]\n",
    "y = df['ma_cat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63030991e-01,  1.63890259e-01, -7.74358640e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-3.63030991e-01,  2.59405503e+00, -1.12630579e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01],\n",
       "       [-3.63030991e-01, -3.03379665e-14, -1.12630579e+00,\n",
       "         2.02688551e+00, -5.90206435e-01],\n",
       "       [-4.71069833e-01,  1.81680631e-01, -7.19933824e-01,\n",
       "        -1.65104665e-14,  2.65105499e+00],\n",
       "       [-4.71069833e-01,  2.23468952e+00, -1.03922608e+00,\n",
       "        -1.65104665e-14, -5.90206435e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Before SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "1333/1333 [==============================] - 1s 590us/step - loss: 0.5131 - accuracy: 0.8927\n",
      "Epoch 2/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2780 - accuracy: 0.9415\n",
      "Epoch 3/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2301 - accuracy: 0.9415\n",
      "Epoch 4/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.2225 - accuracy: 0.9415\n",
      "Epoch 5/100\n",
      "1333/1333 [==============================] - 0s 168us/step - loss: 0.2199 - accuracy: 0.9415\n",
      "Epoch 6/100\n",
      "1333/1333 [==============================] - 0s 159us/step - loss: 0.2177 - accuracy: 0.9415\n",
      "Epoch 7/100\n",
      "1333/1333 [==============================] - 0s 217us/step - loss: 0.2164 - accuracy: 0.9415\n",
      "Epoch 8/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2146 - accuracy: 0.9415\n",
      "Epoch 9/100\n",
      "1333/1333 [==============================] - 0s 176us/step - loss: 0.2139 - accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.2126 - accuracy: 0.9415\n",
      "Epoch 11/100\n",
      "1333/1333 [==============================] - 0s 163us/step - loss: 0.2116 - accuracy: 0.9415\n",
      "Epoch 12/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2107 - accuracy: 0.9415\n",
      "Epoch 13/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2102 - accuracy: 0.9415\n",
      "Epoch 14/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2093 - accuracy: 0.9415\n",
      "Epoch 15/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2085 - accuracy: 0.9415\n",
      "Epoch 16/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "1333/1333 [==============================] - 0s 130us/step - loss: 0.2069 - accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "1333/1333 [==============================] - 0s 148us/step - loss: 0.2065 - accuracy: 0.9415\n",
      "Epoch 19/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2058 - accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2051 - accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.2048 - accuracy: 0.9415\n",
      "Epoch 22/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2044 - accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2042 - accuracy: 0.9415\n",
      "Epoch 24/100\n",
      "1333/1333 [==============================] - 0s 145us/step - loss: 0.2034 - accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "1333/1333 [==============================] - 0s 151us/step - loss: 0.2030 - accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2026 - accuracy: 0.9415\n",
      "Epoch 27/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.2019 - accuracy: 0.9415\n",
      "Epoch 28/100\n",
      "1333/1333 [==============================] - 0s 128us/step - loss: 0.2017 - accuracy: 0.9415\n",
      "Epoch 29/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2013 - accuracy: 0.9415\n",
      "Epoch 30/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.2009 - accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.2004 - accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.2000 - accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1992 - accuracy: 0.9415\n",
      "Epoch 34/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1988 - accuracy: 0.9415\n",
      "Epoch 35/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1983 - accuracy: 0.9415\n",
      "Epoch 36/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1979 - accuracy: 0.9415\n",
      "Epoch 37/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1976 - accuracy: 0.9415\n",
      "Epoch 38/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1973 - accuracy: 0.9415\n",
      "Epoch 39/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1965 - accuracy: 0.9415\n",
      "Epoch 40/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1964 - accuracy: 0.9415\n",
      "Epoch 41/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1959 - accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 43/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1950 - accuracy: 0.9415\n",
      "Epoch 44/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1951 - accuracy: 0.9415\n",
      "Epoch 45/100\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.94 - 0s 127us/step - loss: 0.1943 - accuracy: 0.9415\n",
      "Epoch 46/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1936 - accuracy: 0.9415\n",
      "Epoch 47/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1933 - accuracy: 0.9415\n",
      "Epoch 48/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1924 - accuracy: 0.9415\n",
      "Epoch 49/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1925 - accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "1333/1333 [==============================] - 0s 126us/step - loss: 0.1922 - accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "1333/1333 [==============================] - 0s 153us/step - loss: 0.1915 - accuracy: 0.9415\n",
      "Epoch 52/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1909 - accuracy: 0.9415\n",
      "Epoch 53/100\n",
      "1333/1333 [==============================] - 0s 166us/step - loss: 0.1899 - accuracy: 0.9415\n",
      "Epoch 54/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1896 - accuracy: 0.9415\n",
      "Epoch 55/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1895 - accuracy: 0.9415\n",
      "Epoch 56/100\n",
      "1333/1333 [==============================] - 0s 146us/step - loss: 0.1886 - accuracy: 0.9415\n",
      "Epoch 57/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1884 - accuracy: 0.9415\n",
      "Epoch 58/100\n",
      "1333/1333 [==============================] - 0s 143us/step - loss: 0.1879 - accuracy: 0.9415\n",
      "Epoch 59/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1877 - accuracy: 0.9415\n",
      "Epoch 60/100\n",
      "1333/1333 [==============================] - 0s 127us/step - loss: 0.1870 - accuracy: 0.9415\n",
      "Epoch 61/100\n",
      "1333/1333 [==============================] - 0s 134us/step - loss: 0.1859 - accuracy: 0.9415\n",
      "Epoch 62/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1851 - accuracy: 0.9415\n",
      "Epoch 63/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1850 - accuracy: 0.9415\n",
      "Epoch 64/100\n",
      "1333/1333 [==============================] - 0s 135us/step - loss: 0.1849 - accuracy: 0.9415\n",
      "Epoch 65/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1836 - accuracy: 0.9422\n",
      "Epoch 66/100\n",
      "1333/1333 [==============================] - 0s 140us/step - loss: 0.1835 - accuracy: 0.9415\n",
      "Epoch 67/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1834 - accuracy: 0.9422\n",
      "Epoch 68/100\n",
      "1333/1333 [==============================] - 0s 142us/step - loss: 0.1828 - accuracy: 0.9422\n",
      "Epoch 69/100\n",
      "1333/1333 [==============================] - 0s 171us/step - loss: 0.1814 - accuracy: 0.9422\n",
      "Epoch 70/100\n",
      "1333/1333 [==============================] - 0s 144us/step - loss: 0.1818 - accuracy: 0.9430\n",
      "Epoch 71/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1815 - accuracy: 0.9415\n",
      "Epoch 72/100\n",
      "1333/1333 [==============================] - 0s 181us/step - loss: 0.1802 - accuracy: 0.9430\n",
      "Epoch 73/100\n",
      "1333/1333 [==============================] - 0s 152us/step - loss: 0.1800 - accuracy: 0.9415\n",
      "Epoch 74/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1793 - accuracy: 0.9430\n",
      "Epoch 75/100\n",
      "1333/1333 [==============================] - 0s 141us/step - loss: 0.1798 - accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "1333/1333 [==============================] - 0s 131us/step - loss: 0.1790 - accuracy: 0.9430\n",
      "Epoch 77/100\n",
      "1333/1333 [==============================] - 0s 132us/step - loss: 0.1786 - accuracy: 0.9422\n",
      "Epoch 78/100\n",
      "1333/1333 [==============================] - 0s 133us/step - loss: 0.1774 - accuracy: 0.9430\n",
      "Epoch 79/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1772 - accuracy: 0.94300s - loss: 0.1697 - accuracy: 0.\n",
      "Epoch 80/100\n",
      "1333/1333 [==============================] - 0s 125us/step - loss: 0.1772 - accuracy: 0.9422\n",
      "Epoch 81/100\n",
      "1333/1333 [==============================] - 0s 123us/step - loss: 0.1760 - accuracy: 0.9452\n",
      "Epoch 82/100\n",
      "1333/1333 [==============================] - 0s 139us/step - loss: 0.1756 - accuracy: 0.9460\n",
      "Epoch 83/100\n",
      "1333/1333 [==============================] - 0s 173us/step - loss: 0.1769 - accuracy: 0.9430\n",
      "Epoch 84/100\n",
      "1333/1333 [==============================] - 0s 169us/step - loss: 0.1752 - accuracy: 0.9445\n",
      "Epoch 85/100\n",
      "1333/1333 [==============================] - 0s 150us/step - loss: 0.1752 - accuracy: 0.9452\n",
      "Epoch 86/100\n",
      "1333/1333 [==============================] - 0s 136us/step - loss: 0.1754 - accuracy: 0.9445\n",
      "Epoch 87/100\n",
      "1333/1333 [==============================] - 0s 172us/step - loss: 0.1740 - accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "1333/1333 [==============================] - 0s 194us/step - loss: 0.1737 - accuracy: 0.9445\n",
      "Epoch 89/100\n",
      "1333/1333 [==============================] - 0s 175us/step - loss: 0.1731 - accuracy: 0.9437\n",
      "Epoch 90/100\n",
      "1333/1333 [==============================] - 0s 178us/step - loss: 0.1736 - accuracy: 0.9437\n",
      "Epoch 91/100\n",
      "1333/1333 [==============================] - 0s 165us/step - loss: 0.1726 - accuracy: 0.9460\n",
      "Epoch 92/100\n",
      "1333/1333 [==============================] - 0s 186us/step - loss: 0.1724 - accuracy: 0.9445\n",
      "Epoch 93/100\n",
      "1333/1333 [==============================] - 0s 190us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 94/100\n",
      "1333/1333 [==============================] - 0s 184us/step - loss: 0.1720 - accuracy: 0.9452\n",
      "Epoch 95/100\n",
      "1333/1333 [==============================] - 0s 182us/step - loss: 0.1718 - accuracy: 0.9452\n",
      "Epoch 96/100\n",
      "1333/1333 [==============================] - 0s 129us/step - loss: 0.1725 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "1333/1333 [==============================] - 0s 161us/step - loss: 0.1708 - accuracy: 0.9452\n",
      "Epoch 98/100\n",
      "1333/1333 [==============================] - 0s 162us/step - loss: 0.1713 - accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "1333/1333 [==============================] - 0s 124us/step - loss: 0.1711 - accuracy: 0.9452\n",
      "Epoch 100/100\n",
      "1333/1333 [==============================] - 0s 147us/step - loss: 0.1703 - accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x190f857b6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9458041958041958\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       541\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.95       572\n",
      "   macro avg       0.47      0.50      0.49       572\n",
      "weighted avg       0.89      0.95      0.92       572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Sequential()\n",
    "models.add(Dense(12, input_dim=5, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(8, activation='relu'))\n",
    "models.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "models.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mahe\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2510/2510 [==============================] - 1s 461us/step - loss: 0.6796 - accuracy: 0.6143\n",
      "Epoch 2/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.6402 - accuracy: 0.6793\n",
      "Epoch 3/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.5969 - accuracy: 0.7044\n",
      "Epoch 4/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.5735 - accuracy: 0.7060\n",
      "Epoch 5/100\n",
      "2510/2510 [==============================] - 0s 151us/step - loss: 0.5611 - accuracy: 0.7151\n",
      "Epoch 6/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.5510 - accuracy: 0.7195\n",
      "Epoch 7/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.5392 - accuracy: 0.7331\n",
      "Epoch 8/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.5299 - accuracy: 0.7299\n",
      "Epoch 9/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.5192 - accuracy: 0.7434\n",
      "Epoch 10/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.5098 - accuracy: 0.7546\n",
      "Epoch 11/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.4965 - accuracy: 0.7566\n",
      "Epoch 12/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.4832 - accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.4728 - accuracy: 0.7745\n",
      "Epoch 14/100\n",
      "2510/2510 [==============================] - 0s 133us/step - loss: 0.4628 - accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.4496 - accuracy: 0.7916\n",
      "Epoch 16/100\n",
      "2510/2510 [==============================] - 0s 119us/step - loss: 0.4366 - accuracy: 0.7948\n",
      "Epoch 17/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.4286 - accuracy: 0.8036\n",
      "Epoch 18/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.4203 - accuracy: 0.8056\n",
      "Epoch 19/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.4131 - accuracy: 0.8120\n",
      "Epoch 20/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.4065 - accuracy: 0.8191\n",
      "Epoch 21/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3995 - accuracy: 0.8183\n",
      "Epoch 22/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.3932 - accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.3894 - accuracy: 0.8279\n",
      "Epoch 24/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3831 - accuracy: 0.8271\n",
      "Epoch 25/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3831 - accuracy: 0.8231\n",
      "Epoch 26/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3744 - accuracy: 0.8315\n",
      "Epoch 27/100\n",
      "2510/2510 [==============================] - 0s 143us/step - loss: 0.3721 - accuracy: 0.8375\n",
      "Epoch 28/100\n",
      "2510/2510 [==============================] - 0s 153us/step - loss: 0.3665 - accuracy: 0.8414\n",
      "Epoch 29/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.3640 - accuracy: 0.8351\n",
      "Epoch 30/100\n",
      "2510/2510 [==============================] - 0s 149us/step - loss: 0.3629 - accuracy: 0.8410\n",
      "Epoch 31/100\n",
      "2510/2510 [==============================] - 0s 141us/step - loss: 0.3553 - accuracy: 0.8398\n",
      "Epoch 32/100\n",
      "2510/2510 [==============================] - 0s 150us/step - loss: 0.3528 - accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "2510/2510 [==============================] - 0s 147us/step - loss: 0.3515 - accuracy: 0.8418\n",
      "Epoch 34/100\n",
      "2510/2510 [==============================] - 0s 142us/step - loss: 0.3477 - accuracy: 0.8498\n",
      "Epoch 35/100\n",
      "2510/2510 [==============================] - 0s 161us/step - loss: 0.3439 - accuracy: 0.8478\n",
      "Epoch 36/100\n",
      "2510/2510 [==============================] - 0s 167us/step - loss: 0.3415 - accuracy: 0.8502\n",
      "Epoch 37/100\n",
      "2510/2510 [==============================] - 0s 158us/step - loss: 0.3397 - accuracy: 0.8526\n",
      "Epoch 38/100\n",
      "2510/2510 [==============================] - 0s 158us/step - loss: 0.3392 - accuracy: 0.8470\n",
      "Epoch 39/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.3325 - accuracy: 0.8546\n",
      "Epoch 40/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.3321 - accuracy: 0.8586\n",
      "Epoch 41/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.3314 - accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3249 - accuracy: 0.8618\n",
      "Epoch 43/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.3254 - accuracy: 0.8614\n",
      "Epoch 44/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3204 - accuracy: 0.8622\n",
      "Epoch 45/100\n",
      "2510/2510 [==============================] - 0s 125us/step - loss: 0.3190 - accuracy: 0.86100s - loss: 0.3089 - accura\n",
      "Epoch 46/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.3181 - accuracy: 0.8653\n",
      "Epoch 47/100\n",
      "2510/2510 [==============================] - 0s 129us/step - loss: 0.3164 - accuracy: 0.8602\n",
      "Epoch 48/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3120 - accuracy: 0.8673\n",
      "Epoch 49/100\n",
      "2510/2510 [==============================] - 0s 138us/step - loss: 0.3087 - accuracy: 0.8685\n",
      "Epoch 50/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.3050 - accuracy: 0.8745\n",
      "Epoch 51/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.3040 - accuracy: 0.8729\n",
      "Epoch 52/100\n",
      "2510/2510 [==============================] - 0s 132us/step - loss: 0.3017 - accuracy: 0.8717\n",
      "Epoch 53/100\n",
      "2510/2510 [==============================] - 0s 155us/step - loss: 0.3017 - accuracy: 0.8773\n",
      "Epoch 54/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2989 - accuracy: 0.8765\n",
      "Epoch 55/100\n",
      "2510/2510 [==============================] - 0s 127us/step - loss: 0.2961 - accuracy: 0.8777\n",
      "Epoch 56/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2938 - accuracy: 0.8777\n",
      "Epoch 57/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2934 - accuracy: 0.8717\n",
      "Epoch 58/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2909 - accuracy: 0.8801\n",
      "Epoch 59/100\n",
      "2510/2510 [==============================] - 0s 139us/step - loss: 0.2871 - accuracy: 0.8841\n",
      "Epoch 60/100\n",
      "2510/2510 [==============================] - 0s 163us/step - loss: 0.2859 - accuracy: 0.8797\n",
      "Epoch 61/100\n",
      "2510/2510 [==============================] - 0s 135us/step - loss: 0.2862 - accuracy: 0.8793\n",
      "Epoch 62/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.2812 - accuracy: 0.8873\n",
      "Epoch 63/100\n",
      "2510/2510 [==============================] - 0s 126us/step - loss: 0.2814 - accuracy: 0.8821\n",
      "Epoch 64/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2816 - accuracy: 0.8797\n",
      "Epoch 65/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2789 - accuracy: 0.8857\n",
      "Epoch 66/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2773 - accuracy: 0.8880\n",
      "Epoch 67/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2754 - accuracy: 0.8900\n",
      "Epoch 68/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2747 - accuracy: 0.8884\n",
      "Epoch 69/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2743 - accuracy: 0.8892\n",
      "Epoch 70/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2704 - accuracy: 0.8908\n",
      "Epoch 71/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2710 - accuracy: 0.8845\n",
      "Epoch 72/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2686 - accuracy: 0.8904\n",
      "Epoch 73/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2675 - accuracy: 0.8896\n",
      "Epoch 74/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2666 - accuracy: 0.8928\n",
      "Epoch 75/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2656 - accuracy: 0.8920\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2634 - accuracy: 0.8884\n",
      "Epoch 77/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2631 - accuracy: 0.8968\n",
      "Epoch 78/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.2611 - accuracy: 0.8960\n",
      "Epoch 79/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.2598 - accuracy: 0.8908\n",
      "Epoch 80/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2589 - accuracy: 0.8956\n",
      "Epoch 81/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.2608 - accuracy: 0.8956\n",
      "Epoch 82/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2542 - accuracy: 0.8976\n",
      "Epoch 83/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2555 - accuracy: 0.8980\n",
      "Epoch 84/100\n",
      "2510/2510 [==============================] - 0s 137us/step - loss: 0.2528 - accuracy: 0.8996\n",
      "Epoch 85/100\n",
      "2510/2510 [==============================] - 0s 155us/step - loss: 0.2539 - accuracy: 0.9008\n",
      "Epoch 86/100\n",
      "2510/2510 [==============================] - 0s 153us/step - loss: 0.2496 - accuracy: 0.9040\n",
      "Epoch 87/100\n",
      "2510/2510 [==============================] - 0s 146us/step - loss: 0.2520 - accuracy: 0.8984\n",
      "Epoch 88/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2505 - accuracy: 0.8996\n",
      "Epoch 89/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2500 - accuracy: 0.9004\n",
      "Epoch 90/100\n",
      "2510/2510 [==============================] - 0s 122us/step - loss: 0.2476 - accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2504 - accuracy: 0.9012\n",
      "Epoch 92/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2479 - accuracy: 0.9008\n",
      "Epoch 93/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2445 - accuracy: 0.9084\n",
      "Epoch 94/100\n",
      "2510/2510 [==============================] - 0s 120us/step - loss: 0.2421 - accuracy: 0.9052\n",
      "Epoch 95/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2462 - accuracy: 0.9080\n",
      "Epoch 96/100\n",
      "2510/2510 [==============================] - 0s 128us/step - loss: 0.2413 - accuracy: 0.9064\n",
      "Epoch 97/100\n",
      "2510/2510 [==============================] - 0s 130us/step - loss: 0.2394 - accuracy: 0.9104\n",
      "Epoch 98/100\n",
      "2510/2510 [==============================] - 0s 121us/step - loss: 0.2418 - accuracy: 0.9056\n",
      "Epoch 99/100\n",
      "2510/2510 [==============================] - 0s 124us/step - loss: 0.2413 - accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "2510/2510 [==============================] - 0s 123us/step - loss: 0.2399 - accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f2e3ebe518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = models.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531468531468531\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92       541\n",
      "           1       0.22      0.68      0.33        31\n",
      "\n",
      "    accuracy                           0.85       572\n",
      "   macro avg       0.60      0.77      0.63       572\n",
      "weighted avg       0.94      0.85      0.89       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 21  10]\n",
      " [ 74 467]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['mask=1','mask=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.30e-01],\n",
       "       [5.58e-04],\n",
       "       [2.34e-04],\n",
       "       [6.10e-02],\n",
       "       [6.95e-01],\n",
       "       [6.32e-04],\n",
       "       [8.51e-01],\n",
       "       [8.00e-02],\n",
       "       [1.65e-01],\n",
       "       [3.87e-05],\n",
       "       [2.06e-03],\n",
       "       [7.56e-01],\n",
       "       [1.94e-03],\n",
       "       [6.62e-02],\n",
       "       [1.58e-01],\n",
       "       [2.84e-01],\n",
       "       [8.64e-03],\n",
       "       [3.11e-01],\n",
       "       [6.84e-01],\n",
       "       [2.71e-02],\n",
       "       [1.64e-02],\n",
       "       [1.03e-01],\n",
       "       [3.07e-01],\n",
       "       [4.17e-02],\n",
       "       [6.70e-03],\n",
       "       [3.50e-02],\n",
       "       [9.91e-01],\n",
       "       [4.86e-06],\n",
       "       [1.17e-01],\n",
       "       [1.27e-04],\n",
       "       [3.81e-02],\n",
       "       [6.60e-02],\n",
       "       [5.66e-07],\n",
       "       [7.32e-03],\n",
       "       [8.42e-01],\n",
       "       [3.33e-05],\n",
       "       [1.25e-06],\n",
       "       [6.55e-03],\n",
       "       [5.29e-04],\n",
       "       [1.96e-02],\n",
       "       [8.66e-04],\n",
       "       [3.11e-05],\n",
       "       [1.48e-01],\n",
       "       [5.27e-01],\n",
       "       [5.89e-02],\n",
       "       [4.39e-03],\n",
       "       [8.49e-01],\n",
       "       [2.52e-01],\n",
       "       [1.85e-06],\n",
       "       [9.66e-03],\n",
       "       [5.92e-01],\n",
       "       [9.46e-01],\n",
       "       [2.29e-01],\n",
       "       [2.61e-03],\n",
       "       [7.91e-04],\n",
       "       [0.00e+00],\n",
       "       [3.67e-04],\n",
       "       [5.35e-01],\n",
       "       [9.34e-01],\n",
       "       [9.10e-01],\n",
       "       [1.37e-02],\n",
       "       [1.26e-01],\n",
       "       [8.08e-03],\n",
       "       [1.79e-02],\n",
       "       [6.43e-01],\n",
       "       [8.68e-01],\n",
       "       [8.40e-01],\n",
       "       [0.00e+00],\n",
       "       [1.76e-06],\n",
       "       [2.52e-01],\n",
       "       [1.02e-05],\n",
       "       [2.18e-05],\n",
       "       [3.23e-02],\n",
       "       [1.64e-01],\n",
       "       [2.02e-02],\n",
       "       [7.51e-01],\n",
       "       [7.26e-02],\n",
       "       [7.37e-01],\n",
       "       [0.00e+00],\n",
       "       [8.31e-06],\n",
       "       [8.15e-02],\n",
       "       [3.02e-03],\n",
       "       [1.36e-01],\n",
       "       [1.25e-03],\n",
       "       [3.21e-04],\n",
       "       [9.85e-01],\n",
       "       [5.88e-01],\n",
       "       [5.96e-08],\n",
       "       [2.96e-03],\n",
       "       [2.90e-01],\n",
       "       [8.84e-02],\n",
       "       [7.35e-04],\n",
       "       [4.02e-06],\n",
       "       [4.77e-04],\n",
       "       [8.78e-04],\n",
       "       [7.94e-01],\n",
       "       [1.44e-02],\n",
       "       [6.64e-04],\n",
       "       [1.80e-01],\n",
       "       [9.37e-01],\n",
       "       [3.64e-05],\n",
       "       [5.81e-02],\n",
       "       [0.00e+00],\n",
       "       [5.65e-04],\n",
       "       [9.82e-01],\n",
       "       [1.97e-03],\n",
       "       [7.05e-01],\n",
       "       [7.17e-01],\n",
       "       [4.33e-01],\n",
       "       [6.26e-07],\n",
       "       [6.26e-01],\n",
       "       [0.00e+00],\n",
       "       [2.66e-03],\n",
       "       [6.80e-03],\n",
       "       [8.47e-01],\n",
       "       [9.25e-01],\n",
       "       [8.79e-05],\n",
       "       [2.01e-04],\n",
       "       [9.71e-01],\n",
       "       [1.26e-01],\n",
       "       [4.97e-03],\n",
       "       [4.36e-02],\n",
       "       [1.03e-02],\n",
       "       [3.26e-02],\n",
       "       [7.69e-03],\n",
       "       [6.63e-02],\n",
       "       [5.85e-05],\n",
       "       [8.54e-02],\n",
       "       [1.49e-07],\n",
       "       [5.48e-03],\n",
       "       [1.32e-01],\n",
       "       [8.89e-04],\n",
       "       [8.68e-02],\n",
       "       [3.06e-01],\n",
       "       [3.15e-02],\n",
       "       [9.45e-02],\n",
       "       [5.08e-03],\n",
       "       [1.17e-05],\n",
       "       [9.86e-01],\n",
       "       [4.17e-07],\n",
       "       [3.11e-01],\n",
       "       [0.00e+00],\n",
       "       [5.83e-05],\n",
       "       [7.98e-01],\n",
       "       [1.15e-05],\n",
       "       [8.22e-03],\n",
       "       [2.20e-01],\n",
       "       [5.51e-03],\n",
       "       [4.35e-01],\n",
       "       [6.34e-04],\n",
       "       [8.71e-01],\n",
       "       [9.93e-01],\n",
       "       [1.08e-03],\n",
       "       [4.87e-04],\n",
       "       [2.95e-04],\n",
       "       [9.63e-04],\n",
       "       [1.19e-07],\n",
       "       [6.54e-02],\n",
       "       [1.13e-04],\n",
       "       [9.58e-01],\n",
       "       [3.15e-04],\n",
       "       [5.53e-03],\n",
       "       [8.80e-02],\n",
       "       [1.38e-01],\n",
       "       [1.18e-05],\n",
       "       [6.64e-01],\n",
       "       [9.38e-01],\n",
       "       [7.23e-05],\n",
       "       [1.76e-02],\n",
       "       [2.24e-05],\n",
       "       [1.91e-01],\n",
       "       [3.49e-01],\n",
       "       [3.16e-06],\n",
       "       [3.40e-01],\n",
       "       [8.05e-07],\n",
       "       [1.75e-02],\n",
       "       [4.02e-06],\n",
       "       [1.36e-01],\n",
       "       [6.57e-02],\n",
       "       [9.41e-02],\n",
       "       [3.75e-01],\n",
       "       [1.87e-02],\n",
       "       [1.43e-06],\n",
       "       [2.48e-01],\n",
       "       [6.61e-02],\n",
       "       [2.98e-08],\n",
       "       [3.13e-04],\n",
       "       [4.47e-01],\n",
       "       [1.80e-01],\n",
       "       [5.32e-05],\n",
       "       [4.61e-02],\n",
       "       [2.12e-01],\n",
       "       [1.82e-02],\n",
       "       [6.38e-02],\n",
       "       [2.54e-05],\n",
       "       [3.01e-06],\n",
       "       [1.50e-01],\n",
       "       [2.28e-01],\n",
       "       [7.32e-01],\n",
       "       [4.45e-02],\n",
       "       [2.95e-02],\n",
       "       [2.57e-02],\n",
       "       [3.27e-01],\n",
       "       [2.50e-02],\n",
       "       [0.00e+00],\n",
       "       [4.77e-02],\n",
       "       [3.28e-07],\n",
       "       [2.12e-01],\n",
       "       [3.47e-04],\n",
       "       [1.02e-01],\n",
       "       [8.89e-01],\n",
       "       [6.17e-03],\n",
       "       [6.93e-01],\n",
       "       [3.50e-02],\n",
       "       [1.49e-07],\n",
       "       [8.99e-01],\n",
       "       [2.61e-01],\n",
       "       [1.62e-04],\n",
       "       [1.28e-02],\n",
       "       [1.70e-02],\n",
       "       [8.62e-02],\n",
       "       [5.27e-01],\n",
       "       [5.07e-02],\n",
       "       [2.43e-04],\n",
       "       [6.30e-02],\n",
       "       [4.25e-01],\n",
       "       [4.97e-01],\n",
       "       [7.37e-01],\n",
       "       [1.35e-01],\n",
       "       [0.00e+00],\n",
       "       [1.43e-05],\n",
       "       [8.38e-05],\n",
       "       [2.95e-01],\n",
       "       [9.32e-01],\n",
       "       [4.77e-04],\n",
       "       [2.71e-01],\n",
       "       [1.93e-01],\n",
       "       [1.63e-03],\n",
       "       [2.48e-01],\n",
       "       [1.86e-01],\n",
       "       [1.52e-01],\n",
       "       [6.41e-03],\n",
       "       [7.41e-01],\n",
       "       [1.46e-01],\n",
       "       [2.15e-01],\n",
       "       [2.46e-04],\n",
       "       [7.03e-01],\n",
       "       [7.79e-01],\n",
       "       [9.34e-01],\n",
       "       [3.26e-01],\n",
       "       [1.09e-01],\n",
       "       [1.15e-04],\n",
       "       [2.84e-02],\n",
       "       [5.17e-03],\n",
       "       [1.81e-02],\n",
       "       [1.50e-01],\n",
       "       [1.01e-02],\n",
       "       [2.63e-01],\n",
       "       [5.05e-02],\n",
       "       [6.99e-01],\n",
       "       [4.02e-06],\n",
       "       [5.46e-01],\n",
       "       [3.29e-05],\n",
       "       [1.79e-07],\n",
       "       [3.87e-07],\n",
       "       [2.05e-01],\n",
       "       [1.39e-01],\n",
       "       [3.46e-03],\n",
       "       [1.95e-01],\n",
       "       [2.01e-02],\n",
       "       [5.27e-01],\n",
       "       [4.04e-02],\n",
       "       [3.99e-01],\n",
       "       [7.07e-01],\n",
       "       [5.99e-02],\n",
       "       [1.41e-03],\n",
       "       [5.56e-03],\n",
       "       [1.91e-01],\n",
       "       [2.35e-04],\n",
       "       [4.84e-03],\n",
       "       [2.33e-03],\n",
       "       [1.05e-01],\n",
       "       [4.03e-01],\n",
       "       [8.20e-01],\n",
       "       [6.52e-02],\n",
       "       [1.40e-01],\n",
       "       [2.59e-04],\n",
       "       [9.99e-05],\n",
       "       [3.00e-04],\n",
       "       [7.08e-01],\n",
       "       [1.87e-02],\n",
       "       [6.38e-03],\n",
       "       [0.00e+00],\n",
       "       [0.00e+00],\n",
       "       [7.84e-01],\n",
       "       [1.88e-02],\n",
       "       [7.00e-01],\n",
       "       [8.79e-05],\n",
       "       [6.09e-04],\n",
       "       [1.09e-02],\n",
       "       [6.78e-01],\n",
       "       [9.60e-01],\n",
       "       [6.13e-05],\n",
       "       [1.19e-01],\n",
       "       [3.92e-04],\n",
       "       [3.54e-02],\n",
       "       [5.39e-01],\n",
       "       [9.83e-01],\n",
       "       [9.14e-02],\n",
       "       [3.88e-01],\n",
       "       [1.74e-02],\n",
       "       [4.53e-02],\n",
       "       [5.43e-02],\n",
       "       [1.21e-05],\n",
       "       [1.34e-01],\n",
       "       [4.09e-01],\n",
       "       [6.65e-03],\n",
       "       [1.23e-01],\n",
       "       [8.81e-01],\n",
       "       [4.15e-03],\n",
       "       [3.60e-01],\n",
       "       [6.10e-01],\n",
       "       [8.74e-01],\n",
       "       [3.15e-01],\n",
       "       [7.61e-03],\n",
       "       [3.19e-01],\n",
       "       [4.82e-02],\n",
       "       [2.98e-02],\n",
       "       [4.10e-02],\n",
       "       [1.73e-05],\n",
       "       [6.50e-03],\n",
       "       [6.93e-04],\n",
       "       [5.14e-03],\n",
       "       [1.29e-01],\n",
       "       [1.50e-05],\n",
       "       [2.64e-04],\n",
       "       [7.31e-02],\n",
       "       [2.47e-02],\n",
       "       [7.22e-01],\n",
       "       [2.50e-01],\n",
       "       [2.34e-04],\n",
       "       [6.24e-02],\n",
       "       [1.53e-01],\n",
       "       [5.32e-03],\n",
       "       [8.40e-02],\n",
       "       [2.89e-02],\n",
       "       [8.02e-02],\n",
       "       [8.82e-01],\n",
       "       [1.74e-02],\n",
       "       [7.86e-03],\n",
       "       [5.83e-01],\n",
       "       [8.89e-04],\n",
       "       [0.00e+00],\n",
       "       [1.01e-01],\n",
       "       [1.95e-03],\n",
       "       [0.00e+00],\n",
       "       [8.01e-02],\n",
       "       [7.66e-02],\n",
       "       [8.22e-02],\n",
       "       [3.20e-02],\n",
       "       [7.92e-01],\n",
       "       [2.45e-01],\n",
       "       [2.36e-02],\n",
       "       [5.31e-03],\n",
       "       [3.02e-04],\n",
       "       [7.65e-03],\n",
       "       [7.39e-06],\n",
       "       [1.66e-01],\n",
       "       [2.24e-01],\n",
       "       [0.00e+00],\n",
       "       [1.21e-03],\n",
       "       [0.00e+00],\n",
       "       [1.03e-02],\n",
       "       [9.07e-01],\n",
       "       [1.26e-01],\n",
       "       [1.57e-04],\n",
       "       [6.94e-02],\n",
       "       [2.46e-01],\n",
       "       [2.31e-01],\n",
       "       [1.75e-05],\n",
       "       [6.43e-01],\n",
       "       [1.61e-04],\n",
       "       [3.10e-01],\n",
       "       [4.43e-03],\n",
       "       [2.50e-04],\n",
       "       [7.21e-06],\n",
       "       [4.55e-01],\n",
       "       [1.41e-03],\n",
       "       [3.03e-01],\n",
       "       [0.00e+00],\n",
       "       [8.99e-04],\n",
       "       [7.19e-03],\n",
       "       [3.67e-06],\n",
       "       [6.26e-07],\n",
       "       [2.54e-01],\n",
       "       [2.99e-02],\n",
       "       [3.18e-01],\n",
       "       [4.44e-01],\n",
       "       [2.09e-03],\n",
       "       [4.21e-01],\n",
       "       [3.35e-02],\n",
       "       [7.54e-01],\n",
       "       [3.65e-02],\n",
       "       [5.65e-03],\n",
       "       [5.95e-03],\n",
       "       [4.65e-01],\n",
       "       [1.80e-03],\n",
       "       [4.03e-02],\n",
       "       [7.94e-01],\n",
       "       [3.28e-02],\n",
       "       [1.66e-01],\n",
       "       [4.77e-07],\n",
       "       [3.28e-01],\n",
       "       [1.64e-03],\n",
       "       [3.39e-01],\n",
       "       [3.66e-02],\n",
       "       [2.46e-04],\n",
       "       [6.80e-01],\n",
       "       [6.44e-04],\n",
       "       [2.58e-03],\n",
       "       [0.00e+00],\n",
       "       [2.24e-01],\n",
       "       [1.12e-02],\n",
       "       [2.09e-07],\n",
       "       [3.73e-02],\n",
       "       [2.23e-03],\n",
       "       [1.54e-01],\n",
       "       [9.07e-03],\n",
       "       [7.68e-05],\n",
       "       [6.17e-01],\n",
       "       [1.18e-01],\n",
       "       [1.95e-01],\n",
       "       [2.54e-03],\n",
       "       [2.84e-01],\n",
       "       [4.83e-03],\n",
       "       [1.43e-03],\n",
       "       [4.72e-03],\n",
       "       [9.86e-01],\n",
       "       [4.10e-01],\n",
       "       [5.12e-01],\n",
       "       [3.08e-03],\n",
       "       [5.99e-01],\n",
       "       [2.27e-03],\n",
       "       [3.87e-04],\n",
       "       [2.98e-08],\n",
       "       [1.08e-01],\n",
       "       [2.53e-05],\n",
       "       [2.02e-02],\n",
       "       [1.20e-01],\n",
       "       [2.61e-02],\n",
       "       [1.14e-02],\n",
       "       [2.14e-05],\n",
       "       [6.07e-02],\n",
       "       [6.70e-04],\n",
       "       [4.56e-01],\n",
       "       [4.51e-02],\n",
       "       [2.04e-02],\n",
       "       [7.82e-01],\n",
       "       [7.49e-02],\n",
       "       [5.11e-02],\n",
       "       [2.84e-01],\n",
       "       [4.05e-01],\n",
       "       [8.54e-01],\n",
       "       [1.17e-04],\n",
       "       [1.94e-02],\n",
       "       [1.81e-02],\n",
       "       [9.64e-01],\n",
       "       [6.66e-01],\n",
       "       [9.40e-02],\n",
       "       [3.47e-01],\n",
       "       [7.96e-04],\n",
       "       [3.26e-01],\n",
       "       [6.59e-02],\n",
       "       [5.30e-02],\n",
       "       [1.75e-01],\n",
       "       [3.04e-02],\n",
       "       [3.07e-06],\n",
       "       [5.67e-01],\n",
       "       [1.57e-01],\n",
       "       [0.00e+00],\n",
       "       [1.76e-01],\n",
       "       [2.72e-02],\n",
       "       [6.96e-04],\n",
       "       [9.50e-02],\n",
       "       [7.76e-01],\n",
       "       [3.67e-05],\n",
       "       [1.46e-03],\n",
       "       [7.03e-04],\n",
       "       [6.93e-03],\n",
       "       [3.68e-04],\n",
       "       [4.44e-02],\n",
       "       [6.78e-01],\n",
       "       [3.50e-03],\n",
       "       [1.02e-01],\n",
       "       [8.61e-01],\n",
       "       [3.56e-02],\n",
       "       [5.93e-06],\n",
       "       [1.24e-01],\n",
       "       [4.81e-05],\n",
       "       [0.00e+00],\n",
       "       [1.67e-02],\n",
       "       [4.47e-07],\n",
       "       [1.00e-01],\n",
       "       [3.05e-02],\n",
       "       [7.85e-01],\n",
       "       [2.49e-05],\n",
       "       [3.52e-06],\n",
       "       [1.51e-01],\n",
       "       [4.41e-02],\n",
       "       [7.88e-01],\n",
       "       [4.83e-03],\n",
       "       [1.10e-01],\n",
       "       [2.64e-01],\n",
       "       [8.68e-02],\n",
       "       [7.08e-03],\n",
       "       [4.30e-02],\n",
       "       [3.13e-02],\n",
       "       [2.92e-01],\n",
       "       [1.24e-01],\n",
       "       [1.90e-01],\n",
       "       [7.27e-03],\n",
       "       [9.12e-01],\n",
       "       [1.39e-02],\n",
       "       [2.60e-01],\n",
       "       [9.89e-01],\n",
       "       [6.15e-01],\n",
       "       [6.55e-01],\n",
       "       [8.84e-03],\n",
       "       [1.52e-01],\n",
       "       [4.77e-07],\n",
       "       [8.05e-07],\n",
       "       [1.02e-01],\n",
       "       [1.66e-03],\n",
       "       [1.34e-01],\n",
       "       [1.49e-01],\n",
       "       [1.43e-03],\n",
       "       [1.56e-02],\n",
       "       [6.41e-02],\n",
       "       [2.00e-02],\n",
       "       [8.31e-05],\n",
       "       [1.42e-04],\n",
       "       [4.91e-03],\n",
       "       [9.86e-01],\n",
       "       [1.61e-01],\n",
       "       [3.61e-01],\n",
       "       [1.13e-01],\n",
       "       [1.53e-01],\n",
       "       [6.98e-02],\n",
       "       [7.51e-01],\n",
       "       [1.19e-07],\n",
       "       [2.98e-07],\n",
       "       [4.77e-01],\n",
       "       [1.04e-01],\n",
       "       [1.70e-01],\n",
       "       [2.77e-05],\n",
       "       [5.23e-01],\n",
       "       [2.14e-02],\n",
       "       [2.48e-01],\n",
       "       [1.17e-01],\n",
       "       [1.86e-03],\n",
       "       [1.69e-01],\n",
       "       [5.02e-03],\n",
       "       [8.18e-03],\n",
       "       [7.95e-01],\n",
       "       [4.81e-01],\n",
       "       [5.65e-03],\n",
       "       [4.50e-01],\n",
       "       [7.47e-01],\n",
       "       [3.91e-02],\n",
       "       [2.16e-01],\n",
       "       [0.00e+00],\n",
       "       [1.94e-03]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_probs = models.predict_proba(X_test)\n",
    "nn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a1c1e02847e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "nn_probs = nn_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, _ = precision_recall_curve(y_test, nn_probs)\n",
    "f1 = f1_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network: f1=0.333 auc=0.252\n"
     ]
    }
   ],
   "source": [
    "au = auc(rec, prec)\n",
    "print('Neural network: f1=%.3f auc=%.3f' % (f1, au))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rec, prec, marker='.', label='Neural Network')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
